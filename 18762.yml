name: WD-201 | L10 Milestone | Test

on:
  push:
    branches: ["submission-*"]

jobs:
  repo_check:
    runs-on: ubuntu-latest
    outputs:
      getRepoNameOutcome: ${{steps.get-repo-name.outcome}}
      rejectSubmissionOutcome: ${{steps.report-insufficient-commits.outcome}}
      repoName: ${{steps.get-repo-name.outputs.result}}
    steps:
      - name: Check out the parent repository with student submission data
        uses: actions/checkout@v2
      - name: Extract the student submission repo from URL
        uses: actions/github-script@v5
        id: get-repo-name
        continue-on-error: true
        with:
          script: |
            const submission = require('./submission.json')
            const gitURL =  submission.checklist[1].result
            const regex = /(?:git@|https:\/\/)github.com[:\/]([a-zA-Z0-9\-_.]+\/[a-zA-Z0-9\-_.\/]+)$/g
            const repoName = regex.exec(gitURL)[1].replace(/.git$|\/$/, "")
            if (repoName.split("/").length == 2) {
              return repoName
            } else {
              throw "The submitted URL seems to be of a folder inside a repository"
            }
          result-encoding: string
      - name: Report invalid repository URL in submission
        if: steps.get-repo-name.outcome != 'success'
        uses: pupilfirst/actions/grading@v1
        with:
          fail_submission: true
          feedback: The submitted repository URL is either invalid or private. Please make sure that you submit a valid public repository URL and not a link to directory or branch.
        env:
          REVIEW_END_POINT: ${{ secrets.REVIEW_END_POINT }}
          REVIEW_BOT_USER_TOKEN: ${{ secrets.REVIEW_BOT_USER_TOKEN }}
      - name: Check out the repository with student code
        uses: actions/checkout@v2
        if: steps.get-repo-name.outcome == 'success'
        continue-on-error: true
        id: checkout-student-repo
        with:
          repository: ${{steps.get-repo-name.outputs.result}}
          path: submission
          fetch-depth: 0
      - name: Report invalid repository URL in submission
        if: steps.checkout-student-repo.outcome != 'success'
        id: report-invalid-repo
        uses: pupilfirst/actions/grading@v1
        with:
          fail_submission: true
          feedback: The submitted repository URL is either invalid or private. Please make sure that you submit a valid public repository URL.
        env:
          REVIEW_END_POINT: ${{ secrets.REVIEW_END_POINT }}
          REVIEW_BOT_USER_TOKEN: ${{ secrets.REVIEW_BOT_USER_TOKEN }}
      - name: Get the count of commits
        id: get-commit-count
        if: steps.checkout-student-repo.outcome == 'success'
        run: |
          cd submission
          echo $(git rev-list --count HEAD)
          echo "COMMIT_COUNT=$(git rev-list --count HEAD)" >> $GITHUB_OUTPUT
      - name: Check the count of commits and generate outcome
        uses: actions/github-script@v5
        id: check-repo-count
        continue-on-error: true
        with:
          script: |
            const count = ${{steps.get-commit-count.outputs.COMMIT_COUNT}}
            if (count >= 5) {
              return 'success'
            }
          result-encoding: string
      - name: Reporting insufficient commits in the repo
        if: steps.get-commit-count.outcome == 'success' && steps.check-repo-count.outputs.result != 'success'
        id: report-insufficient-commits
        uses: pupilfirst/actions/grading@v1
        with:
          fail_submission: true
          feedback: The submitted repository does not have enough commits to see the history of your work. You should submit the same repository from Level 6 and upwards. Please ensure that the submitted repository has at least five commits to show progression from previous levels.
        env:
          REVIEW_END_POINT: ${{ secrets.REVIEW_END_POINT }}
          REVIEW_BOT_USER_TOKEN: ${{ secrets.REVIEW_BOT_USER_TOKEN }}
  tests:
    needs: repo_check
    if: needs.repo_check.outputs.getRepoNameOutcome == 'success' && needs.repo_check.outputs.rejectSubmissionOutcome == 'skipped'
    runs-on: ubuntu-latest
    timeout-minutes: 5
    services:
      postgres:
        image: postgres:11.7
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: todo_db_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    env:
      PG_DATABASE: database_test
      PG_USER: postgres
      PG_PASSWORD: postgres
    steps:
      - name: Check out the parent repository with student submission data
        uses: actions/checkout@v2
      - name: Check out the repository with student code
        uses: actions/checkout@v2
        continue-on-error: true
        id: checkout-student-repo
        with:
          repository: ${{needs.repo_check.outputs.repoName}}
          path: submission
      - name: Report to LMS tests in progress
        uses: pupilfirst/actions/reporting@v1
        with:
          status: "in_progress"
          description: "The automated tests are in progress"
        env:
          REVIEW_END_POINT: ${{ secrets.REVIEW_END_POINT }}
          REVIEW_BOT_USER_TOKEN: ${{ secrets.REVIEW_BOT_USER_TOKEN }}
      - name: Check out the repository with student code
        uses: actions/checkout@v2
        continue-on-error: true
        id: checkout-solution-repo
        with:
          repository: pupilfirst/wd201-nodejs-solutions
          path: solution
      - name: Copy submission test files to solution
        if: steps.checkout-student-repo.outcome == 'success'
        id: copy-submission-files
        continue-on-error: true
        run: |
          rm -rf solution/l10/__tests__
          cp -r submission/__tests__ solution/l10
          cp submission/app.js solution/l10/app.js
          rm -rf solution/l10/migrations solution/l10/models solution/l10/views
          cp -r submission/migrations solution/l10
          cp -r submission/models solution/l10
          cp -r submission/views solution/l10
      - name: Report missing test files to the LMS by rejecting submission.
        if: steps.copy-submission-files.outcome != 'success'
        id: missing-submission-files
        uses: pupilfirst/actions/grading@v1
        with:
          fail_submission: true
          feedback: The submitted repository URL does not contain one or more of the directories/files required for the application. Please make sure that your repository contains folders __tests__, migrations, models, views and file app.js.
        env:
          REVIEW_END_POINT: ${{ secrets.REVIEW_END_POINT }}
          REVIEW_BOT_USER_TOKEN: ${{ secrets.REVIEW_BOT_USER_TOKEN }}
      - name: Run tests in the solution repo
        continue-on-error: true
        id: run-jest-test
        if: steps.copy-submission-files.outcome == 'success'
        run: |
          cd solution/l10
          npm install
          npm run test
      - name: Use Node.js to generate report
        id: generate-report
        continue-on-error: true
        run: |
          cd solution/l10 && node generateReportFromResults.js
      - name: Report to LMS the outcome of tests.
        uses: pupilfirst/actions/reporting@v1
        if: steps.generate-report.outcome == 'success'
        id: report-test-results
        with:
          status: "completed"
          report_file_path: "solution/l10/report.json"
        env:
          REVIEW_END_POINT: ${{ secrets.REVIEW_END_POINT }}
          REVIEW_BOT_USER_TOKEN: ${{ secrets.REVIEW_BOT_USER_TOKEN }}
      - name: Grade the submission based on test results
        uses: pupilfirst/actions/grading@v1
        if: steps.generate-report.outcome == 'success'
        with:
          report_file_path: "solution/l10/report.json"
        env:
          REVIEW_END_POINT: ${{ secrets.REVIEW_END_POINT }}
          REVIEW_BOT_USER_TOKEN: ${{ secrets.REVIEW_BOT_USER_TOKEN }}
      - name: Report error to LMS
        uses: pupilfirst/actions/reporting@v1
        if: steps.report-test-results.outcome == 'skipped'
        with:
          status: "completed"
          conclusion: "error"
          description: "Automated tests could not be run successfully"
        env:
          REVIEW_END_POINT: ${{ secrets.REVIEW_END_POINT }}
          REVIEW_BOT_USER_TOKEN: ${{ secrets.REVIEW_BOT_USER_TOKEN }}
